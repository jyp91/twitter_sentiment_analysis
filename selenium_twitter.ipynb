{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selenium Tiwitter Web Scraper (Topic: Crypto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set driver and chrome driver path\n",
    "chrome_path = r\"/Users/jinpark/Desktop/chromedriver_mac/chromedriver\"\n",
    "driver = webdriver.Chrome(chrome_path)\n",
    "\n",
    "# Url that I will access to scrape\n",
    "url = u\"https://twitter.com/search?f=news&vertical=news&q=crypto&src=typd\"\n",
    "driver.get(url)\n",
    "time.sleep(1)\n",
    "\n",
    "# Iterate twitter page\n",
    "body = driver.find_element_by_tag_name('body') # Find element body\n",
    "for _ in range(10): # Iterate twitter page down\n",
    "    body.send_keys(Keys.PAGE_DOWN) # Send keys to scroll page down\n",
    "    time.sleep(0.2) # Put computer to sleep and wait until page loads\n",
    "\n",
    "# Scrape tweets\n",
    "tweets = driver.find_elements_by_class_name('tweet-text') # Find class 'tweet-text' that has tweets\n",
    "tweet_list = [] # Empty list to store all tweet texts\n",
    "for tweet in tweets: # Iterate tweet texts \n",
    "    tweet_list.append(tweet.text) # store each tweets into list in text format\n",
    "\n",
    "# Scrape number of comments\n",
    "replies = driver.find_elements_by_class_name('js-actionReply') # Find class 'js-actionReply' number of comments\n",
    "reply_list = [] # Empty list to store all comments\n",
    "for reply in replies: # Iterate comments\n",
    "    reply_list.append(reply.text) # Store each comment info into list\n",
    "comment_counts = [] # Another empty list to get clean data which it stores \"ONLY NUMBER\" of comments\n",
    "for count in reply_list: # Iterate through reply_list \n",
    "    if len(count) > 0: # If length of each comment is greater than 0\n",
    "        comment_counts.append(count[6:]) # append results after index 6 which it contains only the number of comments\n",
    "\n",
    "# Scrape retweets, same process\n",
    "retweets = driver.find_elements_by_class_name('js-actionRetweet')\n",
    "retweets_list = []\n",
    "for retweet in retweets:\n",
    "    retweets_list.append(retweet.text)\n",
    "retweet_counts = []\n",
    "for count in retweets_list:\n",
    "    if len(count) > 0:\n",
    "        retweet_counts.append(count[8:])\n",
    "\n",
    "# Scrape number of likes, same process\n",
    "likes = driver.find_elements_by_class_name('js-actionFavorite')\n",
    "likes_list = []\n",
    "for like in likes:\n",
    "    likes_list.append(like.text)\n",
    "likes_counts = []\n",
    "for count in likes_list:\n",
    "    if len(count) > 0:\n",
    "        likes_counts.append(count[5:])\n",
    "\n",
    "# Scrape dates\n",
    "dates_list = [] # Empty list to store dates. Getting date was bit tricky. To access date format m-d-y, I had to get attribute and find the xpath for the location.\n",
    "dates = [element.get_attribute('title') for element in driver.find_elements_by_xpath('//a[starts-with(@class, \"tweet-timestamp js-permalink js-nav js-tooltip\")]')] \n",
    "for date in dates:\n",
    "    if '-' in date:\n",
    "        dates_list = [date.split(\"-\",1)[1][1:] if '-' in date else date for date in dates]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get only polarity for sentiment analysis\n",
    "# Polarity measures how positive or negative some text is\n",
    "polarity = []\n",
    "for tweet in tweets:\n",
    "    sentiment_analysis = TextBlob(tweet.text).sentiment\n",
    "    polarity.append(sentiment_analysis[0])\n",
    "print(polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get only subjectivity for sentiment analysis\n",
    "# Subjectivity measures how much of an opinion it is versus how factual\n",
    "subjectivity = []\n",
    "for tweet in tweets:\n",
    "    sentiment_analysis = TextBlob(tweet.text).sentiment\n",
    "    subjectivity.append(sentiment_analysis[1])\n",
    "print(subjectivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Put all the data into a dataframe\n",
    "df = pd.DataFrame({'date': dates_list,\n",
    "                   'tweets': tweet_list, \n",
    "                   'comments': comment_counts, \n",
    "                   'retweets': retweet_counts,\n",
    "                   'likes': likes_counts,\n",
    "                   'polarity_level': polarity,\n",
    "                   'subjectivity_level': subjectivity})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make sure if all data shows correct\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change column date to datetime\n",
    "df['date'] = datetime.strptime('15 Mar 2018', '%d %b %Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rearrange columns in order and name dataframe to crypto\n",
    "crypto = df[['date', 'tweets', 'comments', 'likes', 'polarity_level', 'subjectivity_level']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Looks just the way I want it to be\n",
    "crypto.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Twitter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the data as \"webscrape_twitter_crypto_data.csv\" in data folder\n",
    "crypto.to_csv('data/webscrape_twitter_crypto_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
